# ğŸ§  Natural Language Processing (NLP) Course

Welcome to the **Natural Language Processing (NLP)** course repository! This repository contains a series of hands-on labs and a final project that explore core NLP concepts, techniques, and real-world applications using Python, Pandas, Scikit-learn, and Deep Learning.

---

## ğŸ“ Repository Structure

```bash
.
â”œâ”€â”€ labs/         # Hands-on NLP lab exercises
â”‚   â”œâ”€â”€ lab1/     # Data Analysis with Pandas
â”‚   â”œâ”€â”€ lab2/     # NLP Pipeline + Text Preprocessing + BoW & TF-IDF
â”‚   â”œâ”€â”€ lab3/     # Regex & Word Embedding
â”‚   â”œâ”€â”€ lab4/     # Data-Centric vs Model-Centric + Product Review Classifier
â”‚   â”œâ”€â”€ lab5/     # Topic Modeling Using LDA
â”‚   â””â”€â”€ lab6/     # Generative AI Use Case: Dialogue Summarization
â”‚
â””â”€â”€ project/      # Final project: Fake News Detection
    â”œâ”€â”€ notebook/         # Jupyter notebooks for data analysis and modeling
    â”œâ”€â”€ project_report/   # Written report explaining methods and findings
    â””â”€â”€ presentation/     # Final presentation slides

```

---

## ğŸ§ª Labs Overview

Each lab focuses on a different aspect of NLP:

### ğŸ”¹ Lab 1 â€“ Data Analysis with Pandas
- Learn the foundations of data analysis using the **Pandas** library, tailored for working with text datasets.

### ğŸ”¹ Lab 2 â€“ Building an NLP Pipeline
- **Dataset**: Twitter  
- **Tasks**:
  - Raw text preprocessing
  - Cleaning and normalization
  - Bag of Words (BoW) and TF-IDF feature extraction

### ğŸ”¹ Lab 3 â€“ Regex and Word Embedding
- Use **Regular Expressions** for text pattern extraction.
- Apply **Word2Vec** to capture semantic meaning through word embeddings.

### ğŸ”¹ Lab 4 â€“ Data-Centric vs Model-Centric Approaches
- **Focus**: Product review classification (magazine category)
- Understand the difference between:
  - **Data-centric** approaches: improving data quality
  - **Model-centric** approaches: enhancing model performance

### ğŸ”¹ Lab 5 â€“ Topic Modeling Using LDA
- Learn how to uncover hidden topics in a text corpus using **Latent Dirichlet Allocation (LDA)**.

### ğŸ”¹ Lab 6 â€“ Generative AI Use Case
- **Task**: Summarize dialogues
- Leverage **generative models** to understand and compress conversational content.

---

## ğŸ§¾ Final Project â€“ Fake News Detection

This project explores the application of machine learning and deep learning techniques for detecting fake news.

### ğŸ“Š Dataset
- **Source**: Kaggle Fake News Dataset (labeled real vs fake articles)

### ğŸ› ï¸ Techniques Used
- **Text Representation**: TF-IDF, Word2Vec  
- **Classification Models**: Logistic Regression, XGBoost  
- **Advanced Modeling**: BERT-based topic modeling  
- **Evaluation Metrics**: Accuracy, F1-score, and other performance indicators

### âœ… Key Findings
- **XGBoost** and **LSTM** models achieved high accuracy and strong generalization.
- Combining traditional ML with DL techniques improves detection performance significantly.

---

## ğŸ“š Project Contents

- `notebook/` â€“ Complete codebase and exploratory analysis  
- `project_report/` â€“ Detailed explanation of methods, models, and findings  
- `presentation/` â€“ Visual slides summarizing project goals, workflow, and outcomes

---

## ğŸš€ Getting Started

1.**Clone the repository**:
   ```bash
   git clone https://github.com/<your-username>/nlp-course.git
   cd nlp-course
 ```
2.**Install required dependencies**:
   ```bash 
pip install -r requirements.txt
 ```
3.**Explore the labs or project notebooks using Jupyter**:
   ```bash 
jupyter notebook
 ```
---
# Skills Gained
- Text preprocessing & feature extraction
- Sentiment and topic classification
- Word embeddings & semantic representation
- Regular expressions for NLP
- Topic modeling with LDA
- Generative AI and summarization
- Fake news detection with classical and deep models

--- 
Developed by Araa Almarhabi as part of the Natural Language Processing course.







